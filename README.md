# ComputerUseAI - Desktop AI Assistant

A privacy-first desktop AI assistant that observes your screen activity, learns your workflows, and automates repetitive tasksâ€”all running locally on your system.

## ğŸš€ Features

- **Real-time Screen & Audio Capture** - Records your desktop activity with frame differencing optimization
- **Local Speech-to-Text** - Transcribes audio using Whisper.cpp (completely offline)
- **Computer Vision & OCR** - Understands screen content using Tesseract OCR
- **Pattern Recognition** - Learns your workflows using local LLM (Phi-3 Mini)
- **Task Automation** - Executes learned workflows automatically
- **Privacy-First Design** - All processing happens locally, no cloud dependencies
- **Cross-Platform** - Works on Windows, macOS, and Linux

## ğŸ“‹ Requirements

- Python 3.8+
- 4GB+ RAM (8GB recommended for LLM)
- 2GB+ free disk space
- Tesseract OCR installed

## ğŸ› ï¸ Installation

### Quick Start (Windows)

```powershell
# 1. Clone and setup
git clone https://github.com/ComputerUseAI/ComputerUseAI.git
cd ComputerUseAI
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 2. Install dependencies
pip install -r requirements.txt

# 3. Install Tesseract OCR
# Download from: https://github.com/UB-Mannheim/tesseract/wiki

# 4. Download AI models
python tools/model_setup.py

# 5. Run the application
python -m src.main
```

### Quick Start (macOS)

```bash
# 1. Install dependencies
brew install tesseract
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 2. Download models and run
python tools/model_setup.py
python -m src.main
```

### Quick Start (Linux)

```bash
# 1. Install system dependencies
sudo apt install tesseract-ocr python3-venv

# 2. Setup Python environment
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 3. Download models and run
python tools/model_setup.py
python -m src.main
```

## ğŸ¯ Usage

### First Run

1. **Start the Application** - Run `python -m src.main`
2. **Grant Permissions** - Allow screen recording and microphone access when prompted
3. **Configure Settings** - Go to Settings tab to adjust capture quality, storage limits, and privacy settings
4. **Start Recording** - Click "Start Recording" to begin learning your workflows

### Learning Workflows

1. **Perform Your Task** - Do your repetitive task normally (e.g., data entry, file organization)
2. **Let It Learn** - The AI observes your actions and learns the pattern
3. **Review Detected Workflows** - Check the Workflows tab to see what it learned
4. **Enable Automation** - Turn on automation for workflows you want to automate

### Automation

1. **Enable Automation** - Go to Automation tab and check "Enable Automation"
2. **Set Confidence Threshold** - Adjust how confident the AI needs to be before automating
3. **Monitor Execution** - Watch the automation log to see what it's doing
4. **Intervene When Needed** - You can always stop or modify automation

## âš™ï¸ Configuration

### Settings

- **Capture Settings**: FPS, quality, storage limits
- **Privacy Settings**: Exclude specific applications from recording
- **Automation Settings**: Confidence thresholds, execution preferences

### Privacy Controls

- **Application Exclusion**: Blacklist sensitive applications (banking, messaging)
- **Local Processing**: All AI processing happens on your device
- **Data Encryption**: Optional encryption for stored data
- **Auto-Cleanup**: Automatic deletion of old recordings

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Capture       â”‚    â”‚   Processing     â”‚    â”‚   Intelligence   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Screen        â”‚â”€â”€â”€â–¶â”‚ â€¢ Speech-to-Text â”‚â”€â”€â”€â–¶â”‚ â€¢ Local LLM     â”‚
â”‚ â€¢ Audio         â”‚    â”‚ â€¢ OCR            â”‚    â”‚ â€¢ Pattern Rec.  â”‚
â”‚ â€¢ Events        â”‚    â”‚ â€¢ Screen Analysisâ”‚    â”‚ â€¢ Workflow Gen. â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Storage        â”‚    â”‚   Automation    â”‚    â”‚   User Interfaceâ”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ SQLite DB     â”‚    â”‚ â€¢ Computer Use  â”‚    â”‚ â€¢ PyQt6 GUI     â”‚
â”‚ â€¢ File Manager  â”‚    â”‚ â€¢ Workflow Exec â”‚    â”‚ â€¢ System Tray   â”‚
â”‚ â€¢ Cleanup       â”‚    â”‚ â€¢ Verification  â”‚    â”‚ â€¢ Settings      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Development

### Setup Development Environment

```bash
# Install development dependencies
pip install -e ".[dev,build]"

# Run tests
pytest tests/ -v

# Run linting
flake8 src/ tests/
mypy src/

# Format code
black src/ tests/
```

### Building Executables

```bash
# Build for current platform
python build.py

# Build for all platforms
python build.py --platform all

# Using Makefile
make build
```

## ğŸ“š Documentation

- [Architecture Guide](docs/ARCHITECTURE.md) - Detailed system architecture
- [API Reference](docs/API.md) - Code documentation and APIs
- [User Guide](docs/USER_GUIDE.md) - Comprehensive user manual
- [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues and solutions

## ğŸ”’ Privacy & Security

- **Local Processing**: All AI models run on your device
- **No Cloud Dependencies**: No data sent to external servers
- **Encrypted Storage**: Optional encryption for sensitive data
- **Application Exclusion**: Blacklist sensitive applications
- **Open Source**: Full source code available for audit

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) for speech recognition
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) for text extraction
- [Microsoft Phi-3](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf) for local LLM
- [PyQt6](https://www.riverbankcomputing.com/software/pyqt/) for the GUI framework

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/ComputerUseAI/ComputerUseAI/issues)
- **Discussions**: [GitHub Discussions](https://github.com/ComputerUseAI/ComputerUseAI/discussions)
- **Documentation**: [Wiki](https://github.com/ComputerUseAI/ComputerUseAI/wiki)

---

**ComputerUseAI** - Making your computer work smarter, not harder. ğŸ¤–âœ¨